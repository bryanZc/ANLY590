# ANLY590 Neural Network and Deep Learning
This course focuses on the practice and applications of deep learning. We explore foundational concepts,
structuring popular networks and implementing models through technologies such as Tensorflow and Keras. Topics that are explored throughout this course include image recognition, machine translation, and natural language processing. The course provides a high-level overview of many popular network structures and state of the art frameworks. Parallelism, GPU distributed computing and cloud technologies are also introduced along the way given their importance in both inference and parameter fitting phases of model construction in deep networks.

## Office Hours:
Thursdsays (prior to class) in Car Barn by appointment.
Other Section: 
Tuesdays 6:30 - 9:00 in Car Barn 202, taught by Dr. Keegan Hines. It is fine if you need
to attend the other section occasionally, just send advanced notice to myself and Keegan.

## Textbooks:
• Ian Goodfellow, Yoshua Bengio, Aaron Courville, Deep Learning. MIT Press 2016.
• Michael Nielsen. Neural Networks and Deep Learning : http://neuralnetworksanddeeplearning.com/
• Francois Chollet, Deep Learning With Python https://www.manning.com/books/deep-learning-with-
python

## Software and Computers:

Python will be used throughout the course, with a heavy reliance upon
scientific computing libraries such as Numpy, Tensorflow, and Keras. Students are expected to have a
strong working knowledge of Python computing and ability to set up their working environment as needed
on their own laptop. Additionally, we will leverage computing resources from Amazon Web Services and
Google Cloud. Students should ensure they have signed up for a student education account, which provides
free credits to AWS services. We’ll be working with github to upload resources and homework assignments.
Accordingly, students should sign up for an account. Similarly, students should ensure they have access to
Google Collab’s environment: https://colab.research.google.com
Course Website: The course will use Canvas, https://canvas.georgetown.edu/. Announcements, home-
work assignments and solutions, course material such as documentation, links, data sets and notebooks will
all be posted there. You can look up your grades, and online surveys will also be conducted here. It is
recommended that you visit this page once a day (or set up notifications), as announcements will usually
only appear here.

## Prerequisites:

ANLY-511 (Probabilistic Modeling and Statistical Computing), ANLY-512 (Statistical
Learning Theory) or equivalent, Linear Algebra, Multivariable Calculus, comfort with Python.

## Topics To Be Covered:
• Basic concepts: Model accuracy, prediction accuracy, interpretability, supervised and unsupervised
learning, linear and logistic regression, regularization.
• Artificial neural networks, feedforward, activation functions, loss functions
• Non-linear optimization, gradient descent, backpropagation
• Deep learning toolkit: Keras, Tensorflow, AWS
• autoencoders, dense embeddings, dimensionality reduction
• convolutional networks, transfer learning, applications in image processing and NLP
• recurrent networks, LSTM, GRU, applications in NLP
• Potential special topics: GANs, Reinforcement Learning, Multitask Learning, Machine Translation

## Grading Policy:

About 5 homework sets: 25%, 1 hour in-class mid-term exam: 25%, class participation:
10%, final project: 40%. No final exam.

For class participation, expect to be called up to demonstrate group exercises, explain or suggest code,
explain concepts that were discussed previously, formulate questions concerning new material etc.

## Grading Scheme: 
A: 95% or more, A- : 90% or more, B+ : 85% or more, B: 80% or more, B- : 75% or
more, C: 65% or more, D: 55% or more

The break points for these grades may be lowered, but will not be raised.

